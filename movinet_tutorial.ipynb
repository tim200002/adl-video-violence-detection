{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5XUp6LhLgDT",
    "outputId": "21511c9f-d621-4b7b-b47c-222cbcc047ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting av\n",
      "  Downloading av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.2 MB 28 kB/s \n",
      "\u001b[?25hInstalling collected packages: av\n",
      "Successfully installed av-8.0.3\n",
      "--2021-07-30 12:32:33--  https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3102 (3.0K) [text/plain]\n",
      "Saving to: ‘transforms.py’\n",
      "\n",
      "transforms.py       100%[===================>]   3.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-07-30 12:32:33 (48.4 MB/s) - ‘transforms.py’ saved [3102/3102]\n",
      "\n",
      "--2021-07-30 12:32:34--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
      "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
      "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar [following]\n",
      "--2021-07-30 12:32:34--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
      "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2124008126 (2.0G)\n",
      "Saving to: ‘hmdb51_org.rar’\n",
      "\n",
      "hmdb51_org.rar      100%[===================>]   1.98G  38.9MB/s    in 55s     \n",
      "\n",
      "2021-07-30 12:33:29 (36.7 MB/s) - ‘hmdb51_org.rar’ saved [2124008126/2124008126]\n",
      "\n",
      "--2021-07-30 12:33:29--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
      "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
      "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar [following]\n",
      "--2021-07-30 12:33:30--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
      "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 199521 (195K)\n",
      "Saving to: ‘test_train_splits.rar’\n",
      "\n",
      "test_train_splits.r 100%[===================>] 194.84K   688KB/s    in 0.3s    \n",
      "\n",
      "2021-07-30 12:33:30 (688 KB/s) - ‘test_train_splits.rar’ saved [199521/199521]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install av\n",
    "! wget https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
    "# Download HMDB51 data and splits from serre lab website\n",
    "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
    "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEu2JhJK0sO7",
    "outputId": "af81911f-68ba-4afb-ebc5-c490a38d221b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Atze00/MoViNet-pytorch.git@v0.2\n",
      "  Cloning https://github.com/Atze00/MoViNet-pytorch.git (to revision v0.2) to /tmp/pip-req-build-1oz6sjw9\n",
      "  Running command git clone -q https://github.com/Atze00/MoViNet-pytorch.git /tmp/pip-req-build-1oz6sjw9\n",
      "  Running command git checkout -b v0.2 --track origin/v0.2\n",
      "  Switched to a new branch 'v0.2'\n",
      "  Branch 'v0.2' set up to track remote branch 'v0.2' from 'origin'.\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from MoViNet-pytorch==0.2.0) (1.9.0+cu102)\n",
      "Collecting fvcore\n",
      "  Downloading fvcore-0.1.5.post20210730.tar.gz (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 3.7 MB/s \n",
      "\u001b[?25hCollecting einops\n",
      "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore->MoViNet-pytorch==0.2.0) (1.19.5)\n",
      "Collecting yacs>=0.1.6\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 13.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->MoViNet-pytorch==0.2.0) (4.41.1)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->MoViNet-pytorch==0.2.0) (1.1.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->MoViNet-pytorch==0.2.0) (7.1.2)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->MoViNet-pytorch==0.2.0) (0.8.9)\n",
      "Collecting iopath>=0.1.7\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->MoViNet-pytorch==0.2.0) (3.7.4.3)\n",
      "Building wheels for collected packages: MoViNet-pytorch, fvcore\n",
      "  Building wheel for MoViNet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for MoViNet-pytorch: filename=MoViNet_pytorch-0.2.0-py3-none-any.whl size=12025 sha256=daf5155db8c8b150e912021d5aa479ab2ef45bbd3aa5f9c8ae09a87ba9805367\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7vrz8xc3/wheels/59/99/a5/43c18d233e06a21774b6494a17871b37edf6d31308ae0fb822\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20210730-py3-none-any.whl size=60619 sha256=af28fe7c58e39f1f3bf2b06ab696ffe92e3233461dece85520c1993e31a6773c\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/9c/12/9e9331cff3ddb5bb02a818886f0b52f5d160c54efa19d3516a\n",
      "Successfully built MoViNet-pytorch fvcore\n",
      "Installing collected packages: pyyaml, portalocker, yacs, iopath, fvcore, einops, MoViNet-pytorch\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed MoViNet-pytorch-0.2.0 einops-0.3.0 fvcore-0.1.5.post20210730 iopath-0.1.9 portalocker-2.3.0 pyyaml-5.4.1 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/Atze00/MoViNet-pytorch.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdPFmCYjgviY",
    "outputId": "2820e9e1-f348-43ed-b328-0326c0ed0ab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
      "\n",
      "\n",
      "Extracting from test_train_splits.rar\n",
      "\n",
      "Extracting  test_train_splits/brush_hair_test_split1.txt                 \b\b\b\b  0%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/brush_hair_test_split2.txt                 \b\b\b\b  1%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/brush_hair_test_split3.txt                 \b\b\b\b  1%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/cartwheel_test_split1.txt                  \b\b\b\b  2%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/cartwheel_test_split2.txt                  \b\b\b\b  2%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/cartwheel_test_split3.txt                  \b\b\b\b  3%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/catch_test_split1.txt                      \b\b\b\b  4%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/catch_test_split2.txt                      \b\b\b\b  4%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/catch_test_split3.txt                      \b\b\b\b  5%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/chew_test_split1.txt                       \b\b\b\b  5%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/chew_test_split2.txt                       \b\b\b\b  6%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/chew_test_split3.txt                       \b\b\b\b  6%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/clap_test_split1.txt                       \b\b\b\b  7%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/clap_test_split2.txt                       \b\b\b\b  7%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/clap_test_split3.txt                       \b\b\b\b  8%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/climb_stairs_test_split1.txt               \b\b\b\b  9%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/climb_stairs_test_split2.txt               \b\b\b\b 10%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/climb_stairs_test_split3.txt               \b\b\b\b 10%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/climb_test_split1.txt                      \b\b\b\b 11%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/climb_test_split2.txt                      \b\b\b\b 12%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/climb_test_split3.txt                      \b\b\b\b 12%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/dive_test_split1.txt                       \b\b\b\b 13%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/dive_test_split2.txt                       \b\b\b\b 14%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/dive_test_split3.txt                       \b\b\b\b 14%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/draw_sword_test_split1.txt                 \b\b\b\b 15%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/draw_sword_test_split2.txt                 \b\b\b\b 15%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/draw_sword_test_split3.txt                 \b\b\b\b 16%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/dribble_test_split1.txt                    \b\b\b\b 17%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/dribble_test_split2.txt                    \b\b\b\b 17%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/dribble_test_split3.txt                    \b\b\b\b 18%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/drink_test_split1.txt                      \b\b\b\b 19%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/drink_test_split2.txt                      \b\b\b\b 20%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/drink_test_split3.txt                      \b\b\b\b 20%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/eat_test_split1.txt                        \b\b\b\b 21%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/eat_test_split2.txt                        \b\b\b\b 21%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/eat_test_split3.txt                        \b\b\b\b 22%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/fall_floor_test_split1.txt                 \b\b\b\b 23%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/fall_floor_test_split2.txt                 \b\b\b\b 23%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/fall_floor_test_split3.txt                 \b\b\b\b 24%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/fencing_test_split1.txt                    \b\b\b\b 25%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/fencing_test_split2.txt                    \b\b\b\b 25%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/fencing_test_split3.txt                    \b\b\b\b 26%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/flic_flac_test_split1.txt                  \b\b\b\b 26%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/flic_flac_test_split2.txt                  \b\b\b\b 27%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/flic_flac_test_split3.txt                  \b\b\b\b 27%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/golf_test_split1.txt                       \b\b\b\b 28%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/golf_test_split2.txt                       \b\b\b\b 29%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/golf_test_split3.txt                       \b\b\b\b 29%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/handstand_test_split1.txt                  \b\b\b\b 30%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/handstand_test_split2.txt                  \b\b\b\b 31%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/handstand_test_split3.txt                  \b\b\b\b 32%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/hit_test_split1.txt                        \b\b\b\b 32%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/hit_test_split2.txt                        \b\b\b\b 33%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/hit_test_split3.txt                        \b\b\b\b 34%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/hug_test_split1.txt                        \b\b\b\b 34%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/hug_test_split2.txt                        \b\b\b\b 35%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/hug_test_split3.txt                        \b\b\b\b 35%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/jump_test_split1.txt                       \b\b\b\b 36%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/jump_test_split2.txt                       \b\b\b\b 37%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/jump_test_split3.txt                       \b\b\b\b 37%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kick_ball_test_split1.txt                  \b\b\b\b 38%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kick_ball_test_split2.txt                  \b\b\b\b 39%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kick_ball_test_split3.txt                  \b\b\b\b 40%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kick_test_split1.txt                       \b\b\b\b 40%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kick_test_split2.txt                       \b\b\b\b 41%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kick_test_split3.txt                       \b\b\b\b 41%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kiss_test_split1.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kiss_test_split2.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/kiss_test_split3.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/laugh_test_split1.txt                      \b\b\b\b 43%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/laugh_test_split2.txt                      \b\b\b\b 43%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/laugh_test_split3.txt                      \b\b\b\b 44%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pick_test_split1.txt                       \b\b\b\b 45%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pick_test_split2.txt                       \b\b\b\b 45%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pick_test_split3.txt                       \b\b\b\b 46%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pour_test_split1.txt                       \b\b\b\b 47%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pour_test_split2.txt                       \b\b\b\b 48%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pour_test_split3.txt                       \b\b\b\b 48%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pullup_test_split1.txt                     \b\b\b\b 49%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pullup_test_split2.txt                     \b\b\b\b 49%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pullup_test_split3.txt                     \b\b\b\b 50%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/punch_test_split1.txt                      \b\b\b\b 50%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/punch_test_split2.txt                      \b\b\b\b 51%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/punch_test_split3.txt                      \b\b\b\b 52%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pushup_test_split1.txt                     \b\b\b\b 52%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pushup_test_split2.txt                     \b\b\b\b 53%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/pushup_test_split3.txt                     \b\b\b\b 53%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/push_test_split1.txt                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/push_test_split2.txt                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/push_test_split3.txt                       \b\b\b\b 55%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/ride_bike_test_split1.txt                  \b\b\b\b 55%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/ride_bike_test_split2.txt                  \b\b\b\b 56%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/ride_bike_test_split3.txt                  \b\b\b\b 56%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/ride_horse_test_split1.txt                 \b\b\b\b 56%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/ride_horse_test_split2.txt                 \b\b\b\b 57%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/ride_horse_test_split3.txt                 \b\b\b\b 57%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/run_test_split1.txt                        \b\b\b\b 58%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/run_test_split2.txt                        \b\b\b\b 59%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/run_test_split3.txt                        \b\b\b\b 60%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shake_hands_test_split1.txt                \b\b\b\b 62%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shake_hands_test_split2.txt                \b\b\b\b 63%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shake_hands_test_split3.txt                \b\b\b\b 64%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_ball_test_split1.txt                 \b\b\b\b 64%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_ball_test_split2.txt                 \b\b\b\b 65%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_ball_test_split3.txt                 \b\b\b\b 65%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_bow_test_split1.txt                  \b\b\b\b 66%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_bow_test_split2.txt                  \b\b\b\b 66%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_bow_test_split3.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_gun_test_split1.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_gun_test_split2.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/shoot_gun_test_split3.txt                  \b\b\b\b 68%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/situp_test_split1.txt                      \b\b\b\b 69%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/situp_test_split2.txt                      \b\b\b\b 69%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/situp_test_split3.txt                      \b\b\b\b 70%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sit_test_split1.txt                        \b\b\b\b 71%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sit_test_split2.txt                        \b\b\b\b 71%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sit_test_split3.txt                        \b\b\b\b 72%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/smile_test_split1.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/smile_test_split2.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/smile_test_split3.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/smoke_test_split1.txt                      \b\b\b\b 74%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/smoke_test_split2.txt                      \b\b\b\b 74%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/smoke_test_split3.txt                      \b\b\b\b 75%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/somersault_test_split1.txt                 \b\b\b\b 76%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/somersault_test_split2.txt                 \b\b\b\b 76%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/somersault_test_split3.txt                 \b\b\b\b 77%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/stand_test_split1.txt                      \b\b\b\b 78%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/stand_test_split2.txt                      \b\b\b\b 79%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/stand_test_split3.txt                      \b\b\b\b 80%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/swing_baseball_test_split1.txt             \b\b\b\b 80%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/swing_baseball_test_split2.txt             \b\b\b\b 81%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/swing_baseball_test_split3.txt             \b\b\b\b 81%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sword_exercise_test_split1.txt             \b\b\b\b 82%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sword_exercise_test_split2.txt             \b\b\b\b 83%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sword_exercise_test_split3.txt             \b\b\b\b 83%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sword_test_split1.txt                      \b\b\b\b 84%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sword_test_split2.txt                      \b\b\b\b 85%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/sword_test_split3.txt                      \b\b\b\b 86%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/talk_test_split1.txt                       \b\b\b\b 86%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/talk_test_split2.txt                       \b\b\b\b 87%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/talk_test_split3.txt                       \b\b\b\b 87%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/throw_test_split1.txt                      \b\b\b\b 88%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/throw_test_split2.txt                      \b\b\b\b 88%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/throw_test_split3.txt                      \b\b\b\b 89%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/turn_test_split1.txt                       \b\b\b\b 90%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/turn_test_split2.txt                       \b\b\b\b 91%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/turn_test_split3.txt                       \b\b\b\b 92%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/walk_test_split1.txt                       \b\b\b\b 94%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/walk_test_split2.txt                       \b\b\b\b 95%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/walk_test_split3.txt                       \b\b\b\b 97%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/wave_test_split1.txt                       \b\b\b\b 98%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/wave_test_split2.txt                       \b\b\b\b 99%\b\b\b\b\b  OK \n",
      "Extracting  test_train_splits/wave_test_split3.txt                       \b\b\b\b 99%\b\b\b\b\b  OK \n",
      "All OK\n",
      "\n",
      "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
      "\n",
      "\n",
      "Extracting from hmdb51_org.rar\n",
      "\n",
      "Extracting  shoot_gun.rar                                                \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b\b  OK \n",
      "Extracting  sit.rar                                                      \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b\b  OK \n",
      "Extracting  situp.rar                                                    \b\b\b\b  3%\b\b\b\b  4%\b\b\b\b\b  OK \n",
      "Extracting  smile.rar                                                    \b\b\b\b  4%\b\b\b\b  5%\b\b\b\b\b  OK \n",
      "Extracting  smoke.rar                                                    \b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b\b  OK \n",
      "Extracting  somersault.rar                                               \b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b\b  OK \n",
      "Extracting  stand.rar                                                    \b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b\b  OK \n",
      "Extracting  swing_baseball.rar                                           \b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b\b  OK \n",
      "Extracting  sword.rar                                                    \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b\b  OK \n",
      "Extracting  sword_exercise.rar                                           \b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b\b  OK \n",
      "Extracting  talk.rar                                                     \b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b\b  OK \n",
      "Extracting  throw.rar                                                    \b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b\b  OK \n",
      "Extracting  turn.rar                                                     \b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n",
      "Extracting  walk.rar                                                     \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b\b  OK \n",
      "Extracting  wave.rar                                                     \b\b\b\b 32%\b\b\b\b 33%\b\b\b\b\b  OK \n",
      "Extracting  brush_hair.rar                                               \b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b\b  OK \n",
      "Extracting  cartwheel.rar                                                \b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b\b  OK \n",
      "Extracting  catch.rar                                                    \b\b\b\b 39%\b\b\b\b\b  OK \n",
      "Extracting  chew.rar                                                     \b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b\b  OK \n",
      "Extracting  clap.rar                                                     \b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b\b  OK \n",
      "Extracting  climb.rar                                                    \b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b\b  OK \n",
      "Extracting  climb_stairs.rar                                             \b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b\b  OK \n",
      "Extracting  dive.rar                                                     \b\b\b\b 47%\b\b\b\b 48%\b\b\b\b\b  OK \n",
      "Extracting  draw_sword.rar                                               \b\b\b\b 49%\b\b\b\b 50%\b\b\b\b\b  OK \n",
      "Extracting  dribble.rar                                                  \b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b\b  OK \n",
      "Extracting  drink.rar                                                    \b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b\b  OK \n",
      "Extracting  eat.rar                                                      \b\b\b\b 54%\b\b\b\b 55%\b\b\b\b\b  OK \n",
      "Extracting  fall_floor.rar                                               \b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b\b  OK \n",
      "Extracting  fencing.rar                                                  \b\b\b\b 57%\b\b\b\b 58%\b\b\b\b\b  OK \n",
      "Extracting  flic_flac.rar                                                \b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b\b  OK \n",
      "Extracting  golf.rar                                                     \b\b\b\b 60%\b\b\b\b 61%\b\b\b\b\b  OK \n",
      "Extracting  handstand.rar                                                \b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b\b  OK \n",
      "Extracting  hit.rar                                                      \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b\b  OK \n",
      "Extracting  hug.rar                                                      \b\b\b\b 64%\b\b\b\b 65%\b\b\b\b\b  OK \n",
      "Extracting  jump.rar                                                     \b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b\b  OK \n",
      "Extracting  kick.rar                                                     \b\b\b\b 67%\b\b\b\b 68%\b\b\b\b\b  OK \n",
      "Extracting  kick_ball.rar                                                \b\b\b\b 68%\b\b\b\b 69%\b\b\b\b\b  OK \n",
      "Extracting  kiss.rar                                                     \b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b\b  OK \n",
      "Extracting  laugh.rar                                                    \b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b\b  OK \n",
      "Extracting  pick.rar                                                     \b\b\b\b 75%\b\b\b\b 76%\b\b\b\b\b  OK \n",
      "Extracting  pour.rar                                                     \b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b\b  OK \n",
      "Extracting  pullup.rar                                                   \b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n",
      "Extracting  punch.rar                                                    \b\b\b\b 80%\b\b\b\b 81%\b\b\b\b\b  OK \n",
      "Extracting  push.rar                                                     \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b\b  OK \n",
      "Extracting  pushup.rar                                                   \b\b\b\b 83%\b\b\b\b 84%\b\b\b\b\b  OK \n",
      "Extracting  ride_bike.rar                                                \b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b\b  OK \n",
      "Extracting  ride_horse.rar                                               \b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n",
      "Extracting  run.rar                                                      \b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b\b  OK \n",
      "Extracting  shake_hands.rar                                              \b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b\b  OK \n",
      "Extracting  shoot_ball.rar                                               \b\b\b\b 95%\b\b\b\b 96%\b\b\b\b\b  OK \n",
      "Extracting  shoot_bow.rar                                                \b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
      "All OK\n"
     ]
    }
   ],
   "source": [
    "# Extract and organize video data..\n",
    "! mkdir -p video_data test_train_splits\n",
    "! unrar e test_train_splits.rar test_train_splits\n",
    "! rm test_train_splits.rar\n",
    "! unrar e hmdb51_org.rar \n",
    "! rm hmdb51_org.rar\n",
    "! mv *.rar video_data\n",
    "import os\n",
    "for files in os.listdir('video_data'):\n",
    "    foldername = files.split('.')[0]\n",
    "    os.system(\"mkdir -p video_data/\" + foldername)\n",
    "    os.system(\"unrar e video_data/\"+ files + \" video_data/\"+foldername)\n",
    "\n",
    "! rm video_data/*.rar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "d7162af7b4084a999cc709307e40616a",
      "6db30d527fa94b16a6af19e80828d0e6",
      "f5cfea9b48b04fef9df36d118efd1722",
      "15fb89fe0f454fd8a47316c5f4fe50a9",
      "3c70c93bde99420c84c0ad818b2dd7c6",
      "4f419af9ec4e4605b7a5404dee09e33c",
      "fb81268f11db41f4a09cad4206a4e04a",
      "10cf8cfbba5d408f905855995c502fba",
      "df50195d063b402f93d8552336045c3c",
      "39ca1a3fed5c4067a020bd7027b9fbf1",
      "e74d503d808e4c5da75eff1d096590ad",
      "d2724859dc7e48b29fcdb0ab75c75675",
      "56c1bc4a801c41c29dbfb00237703ef4",
      "acb87c19a53c40c5b74353d2ac6f0de6",
      "7543a992a3274c5b944f31361d4ddc4d",
      "7e42e2ea9cad463c8ebe2a54801218b2"
     ]
    },
    "id": "JpChe2ZX2-Zq",
    "outputId": "9b989e52-7ea4-4055-8937-4d2801af94dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/423 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 423/423 [00:38<00:00, 10.90it/s]\n",
      "/home/sangyoonyu/workspace/ADL/venv/lib/python3.10/site-packages/torchvision/datasets/video_utils.py:219: UserWarning: There aren't enough frames in the current video to get a clip for the given clip length and frames between clips. The video (and potentially others) will be skipped.\n",
      "  warnings.warn(\n",
      "100%|██████████| 423/423 [00:38<00:00, 10.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "import transforms as T\n",
    "from movinets import MoViNet\n",
    "from movinets.config import _C\n",
    "from HMDB51 import HMDB51_to_ViolenceWrapper\n",
    "\n",
    "torch.manual_seed(97)\n",
    "num_frames = 16 # 16\n",
    "clip_steps = 2\n",
    "Bs_Train = 16\n",
    "Bs_Test = 16\n",
    "\n",
    "transform = transforms.Compose([  \n",
    "                                                     \n",
    "                                 T.ToFloatTensorInZeroOne(),\n",
    "                                 T.Resize((200, 200)),\n",
    "                                 T.RandomHorizontalFlip(),\n",
    "                                 #T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
    "                                 T.RandomCrop((172, 172))])\n",
    "transform_test = transforms.Compose([                           \n",
    "                                 T.ToFloatTensorInZeroOne(),\n",
    "                                 T.Resize((200, 200)),\n",
    "                                 #T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
    "                                 T.CenterCrop((172, 172))])\n",
    "\n",
    "hmdb51_train = HMDB51_to_ViolenceWrapper('video_data/', train=True, clip_steps=clip_steps, transform=transform, num_frames=num_frames)\n",
    "\n",
    "hmdb51_test = HMDB51_to_ViolenceWrapper('video_data/', train=False, clip_steps=clip_steps, transform=transform_test, num_frames=num_frames)\n",
    "\n",
    "train_loader = DataLoader(hmdb51_train, batch_size=Bs_Train, shuffle=True)\n",
    "test_loader  = DataLoader(hmdb51_test, batch_size=Bs_Test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wUawNw9scph7"
   },
   "outputs": [],
   "source": [
    "def train_iter(model, optimz, data_load, loss_val):\n",
    "    samples = len(data_load.dataset)\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    model.clean_activation_buffers()\n",
    "    optimz.zero_grad()\n",
    "    for i, (data, target) in enumerate(data_load):\n",
    "        out = F.log_softmax(model(data.cuda()), dim=1)\n",
    "        loss = F.nll_loss(out, target.cuda())\n",
    "        loss.backward()\n",
    "        optimz.step()\n",
    "        optimz.zero_grad()\n",
    "        model.clean_activation_buffers()\n",
    "        if i % 50 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_load)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "            loss_val.append(loss.item())\n",
    " \n",
    "def evaluate(model, data_load, loss_val):\n",
    "    model.eval()\n",
    "    \n",
    "    samples = len(data_load.dataset)\n",
    "    csamp = 0\n",
    "    tloss = 0\n",
    "    model.clean_activation_buffers()\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_load:\n",
    "            output = F.log_softmax(model(data.cuda()), dim=1)\n",
    "            loss = F.nll_loss(output, target.cuda(), reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            \n",
    "            tloss += loss.item()\n",
    "            csamp += pred.eq(target.cuda()).sum()\n",
    "            model.clean_activation_buffers()\n",
    "    aloss = tloss / samples\n",
    "    loss_val.append(aloss)\n",
    "    print('\\nAverage test loss: ' + '{:.4f}'.format(aloss) +\n",
    "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
    "          '{:5}'.format(samples) + ' (' +\n",
    "          '{:4.2f}'.format(100.0 * csamp / samples) + '%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangyoonyu/workspace/ADL/venv/lib/python3.10/site-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average test loss: 2.6112  Accuracy:  696/ 2945 (23.63%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 2, (1,1,1))\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "# load model from checkpoint\n",
    "model.load_state_dict(torch.load('checkpoint/best.pt'))\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "loss_val = []\n",
    "evaluate(model, test_loader, loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wg7PxA5YcrhS",
    "outputId": "3a5e2b8c-9036-4f22-c00e-933f0e092de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/ 7520 (  0%)]  Loss: 0.6920\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.3196\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.3332\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.2180\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.0633\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.1269\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.0231\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.0220\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.0281\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.0546\n",
      "\n",
      "Average test loss: 0.1394  Accuracy: 2797/ 2945 (94.97%)\n",
      "\n",
      "Epoch: 2\n",
      "[    0/ 7520 (  0%)]  Loss: 0.0133\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.0362\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.0048\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.0034\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.0031\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.0034\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.0011\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.0031\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.0008\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.0026\n",
      "\n",
      "Average test loss: 0.2044  Accuracy: 2784/ 2945 (94.53%)\n",
      "\n",
      "Execution time: 1196.29 seconds\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2\n",
    "\n",
    "# Full FT\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 2, (1,1,1))\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangyoonyu/workspace/ADL/venv/lib/python3.10/site-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0/ 7520 (  0%)]  Loss: 0.7021\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.6885\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.6712\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.6688\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.6784\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.6394\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.6139\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.6282\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.5781\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.6103\n",
      "\n",
      "Average test loss: 0.6175  Accuracy: 2610/ 2945 (88.62%)\n",
      "\n",
      "Epoch: 2\n",
      "[    0/ 7520 (  0%)]  Loss: 0.6087\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.5688\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.6276\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.5743\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.5496\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.5873\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.5474\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.5366\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.5233\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.5644\n",
      "\n",
      "Average test loss: 0.5526  Accuracy: 2716/ 2945 (92.22%)\n",
      "\n",
      "Execution time: 1309.58 seconds\n"
     ]
    }
   ],
   "source": [
    "# Head FT\n",
    "N_EPOCHS = 2\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "# freeze model except last layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 2, (1,1,1))\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/ 7520 (  0%)]  Loss: 0.6927\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.5976\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.4098\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.3500\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.3029\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.2082\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.4062\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.2735\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.2531\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.2841\n",
      "\n",
      "Average test loss: 0.2432  Accuracy: 2769/ 2945 (94.02%)\n",
      "\n",
      "Epoch: 2\n",
      "[    0/ 7520 (  0%)]  Loss: 0.2829\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.3504\n"
     ]
    }
   ],
   "source": [
    "# Head MLP FT\n",
    "N_EPOCHS = 2\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "# freeze model except classifier MLP layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 2, (1,1,1))\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FDQ1N2E12H7Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.69 MiB is free. Including non-PyTorch memory, this process has 4.00 GiB memory in use. Process 1776135 has 2.14 GiB memory in use. Process 1784702 has 17.52 GiB memory in use. Of the allocated memory 3.56 GiB is allocated by PyTorch, and 132.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, N_EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch:\u001b[39m\u001b[39m'\u001b[39m, epoch)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     train_iter(model, optimz, train_loader, trloss_val)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     evaluate(model, test_loader, tsloss_val)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mExecution time:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m{:5.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time), \u001b[39m'\u001b[39m\u001b[39mseconds\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m optimz\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_load):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mlog_softmax(model(data\u001b[39m.\u001b[39;49mcuda()), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(out, target\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:651\u001b[0m, in \u001b[0;36mMoViNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 651\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:642\u001b[0m, in \u001b[0;36mMoViNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    641\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m--> 642\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(x)\n\u001b[1;32m    643\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv7(x)\n\u001b[1;32m    644\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg(x)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:504\u001b[0m, in \u001b[0;36mBasicBneck.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    502\u001b[0m     residual \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 504\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:262\u001b[0m, in \u001b[0;36mConvBlock3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_like:\n\u001b[1;32m    259\u001b[0m     x \u001b[39m=\u001b[39m same_padding(x, x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    260\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    261\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 262\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(x)\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:242\u001b[0m, in \u001b[0;36mConvBlock3D._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2plus1d\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    241\u001b[0m     x \u001b[39m=\u001b[39m rearrange(x, \u001b[39m\"\u001b[39m\u001b[39mb c t h w -> (b t) c h w\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 242\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_1(x)\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2plus1d\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    244\u001b[0m     x \u001b[39m=\u001b[39m rearrange(x,\n\u001b[1;32m    245\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m(b t) c h w -> b c t h w\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m                   t\u001b[39m=\u001b[39mshape_with_buffer[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:29\u001b[0m, in \u001b[0;36mSwish.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49msigmoid(x)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.69 MiB is free. Including non-PyTorch memory, this process has 4.00 GiB memory in use. Process 1776135 has 2.14 GiB memory in use. Process 1784702 has 17.52 GiB memory in use. Of the allocated memory 3.56 GiB is allocated by PyTorch, and 132.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# First and Head FT\n",
    "N_EPOCHS = 2\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "# freeze model except first, last layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 2, (1,1,1))\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/ 7520 (  0%)]  Loss: 3.9341\n",
      "[  800/ 7520 ( 11%)]  Loss: 3.8683\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 3.7530\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 3.5150\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 3.2698\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 2.8049\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 2.2856\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 2.0012\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 2.2784\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 1.6320\n",
      "\n",
      "Average test loss: 1.6970  Accuracy: 1934/ 2945 (65.67%)\n",
      "\n",
      "Execution time: 537.16 seconds\n"
     ]
    }
   ],
   "source": [
    "# Conv1, Blocks and Head FT\n",
    "N_EPOCHS = 2\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "# freeze model except conv1, blocks and last layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.blocks.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 51, (1,1,1))\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangyoonyu/workspace/ADL/venv/lib/python3.10/site-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 99.62 MiB is free. Process 72943 has 18.09 GiB memory in use. Including non-PyTorch memory, this process has 5.49 GiB memory in use. Of the allocated memory 5.05 GiB is allocated by PyTorch, and 145.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, N_EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch:\u001b[39m\u001b[39m'\u001b[39m, epoch)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     train_iter(model, optimz, train_loader, trloss_val)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     evaluate(model, test_loader, tsloss_val)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mExecution time:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m{:5.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time), \u001b[39m'\u001b[39m\u001b[39mseconds\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (data,_ , target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_load):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# target 0 if not violence, 1 if violence\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m target[i] \u001b[39min\u001b[39;00m violence_idx \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(target))])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mlog_softmax(model(data\u001b[39m.\u001b[39;49mcuda()), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(out, target\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bspica/home/sangyoonyu/workspace/ADL/movinet_tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:651\u001b[0m, in \u001b[0;36mMoViNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 651\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:642\u001b[0m, in \u001b[0;36mMoViNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    641\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m--> 642\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(x)\n\u001b[1;32m    643\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv7(x)\n\u001b[1;32m    644\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg(x)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:504\u001b[0m, in \u001b[0;36mBasicBneck.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    502\u001b[0m     residual \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 504\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:262\u001b[0m, in \u001b[0;36mConvBlock3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_like:\n\u001b[1;32m    259\u001b[0m     x \u001b[39m=\u001b[39m same_padding(x, x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    260\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    261\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 262\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(x)\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:242\u001b[0m, in \u001b[0;36mConvBlock3D._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2plus1d\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    241\u001b[0m     x \u001b[39m=\u001b[39m rearrange(x, \u001b[39m\"\u001b[39m\u001b[39mb c t h w -> (b t) c h w\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 242\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_1(x)\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2plus1d\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    244\u001b[0m     x \u001b[39m=\u001b[39m rearrange(x,\n\u001b[1;32m    245\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m(b t) c h w -> b c t h w\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m                   t\u001b[39m=\u001b[39mshape_with_buffer[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/ADL/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/ADL/movinets/models.py:29\u001b[0m, in \u001b[0;36mSwish.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39;49msigmoid(x)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 99.62 MiB is free. Process 72943 has 18.09 GiB memory in use. Including non-PyTorch memory, this process has 5.49 GiB memory in use. Of the allocated memory 5.05 GiB is allocated by PyTorch, and 145.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Blocks and Head FT\n",
    "N_EPOCHS = 2\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "# freeze model except blocks and last layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.blocks.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 2, (1,1,1))\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangyoonyu/workspace/ADL/venv/lib/python3.10/site-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0/ 7520 (  0%)]  Loss: 0.7040\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.6532\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.5148\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.3706\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.3163\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.1021\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.0810\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.1422\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.0243\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.0126\n",
      "\n",
      "Average test loss: 0.1233  Accuracy: 2830/ 2945 (96.10%)\n",
      "\n",
      "Epoch: 2\n",
      "[    0/ 7520 (  0%)]  Loss: 0.0148\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.0141\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.0338\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.0128\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.0102\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.0081\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.0040\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.0172\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.0033\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.0137\n",
      "\n",
      "Average test loss: 0.1228  Accuracy: 2820/ 2945 (95.76%)\n",
      "\n",
      "Execution time: 1105.53 seconds\n"
     ]
    }
   ],
   "source": [
    "# Blocks, conv7 and head FT\n",
    "N_EPOCHS = 2\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "# freeze conv1 layer\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 2, (1,1,1))\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/ 7520 (  0%)]  Loss: 0.6934\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.5516\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.4516\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.2586\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.2466\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.3309\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.4224\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.1148\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.4853\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.1583\n",
      "\n",
      "Average test loss: 0.1920  Accuracy: 2789/ 2945 (94.70%)\n",
      "\n",
      "Epoch: 2\n",
      "[    0/ 7520 (  0%)]  Loss: 0.1737\n",
      "[  800/ 7520 ( 11%)]  Loss: 0.1667\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 0.0488\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 0.0444\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 0.2826\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 0.1730\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 0.0406\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 0.0921\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 0.0414\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 0.0923\n",
      "\n",
      "Average test loss: 0.1639  Accuracy: 2788/ 2945 (94.67%)\n",
      "\n",
      "Execution time: 1058.32 seconds\n"
     ]
    }
   ],
   "source": [
    "# conv7 and mlp FT\n",
    "N_EPOCHS = 2\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "# freeze conv1 layer\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.blocks.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 2, (1,1,1))\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/ 7520 (  0%)]  Loss: 3.9328\n",
      "[  800/ 7520 ( 11%)]  Loss: 3.8582\n",
      "[ 1600/ 7520 ( 21%)]  Loss: 3.6928\n",
      "[ 2400/ 7520 ( 32%)]  Loss: 3.4207\n",
      "[ 3200/ 7520 ( 43%)]  Loss: 3.0888\n",
      "[ 4000/ 7520 ( 53%)]  Loss: 3.0386\n",
      "[ 4800/ 7520 ( 64%)]  Loss: 2.3549\n",
      "[ 5600/ 7520 ( 74%)]  Loss: 2.4311\n",
      "[ 6400/ 7520 ( 85%)]  Loss: 2.3564\n",
      "[ 7200/ 7520 ( 96%)]  Loss: 1.8804\n",
      "\n",
      "Average test loss: 2.2315  Accuracy: 1756/ 2945 (59.63%)\n",
      "\n",
      "Execution time: 509.30 seconds\n"
     ]
    }
   ],
   "source": [
    "# Blocks and Head FT\n",
    "N_EPOCHS = 2\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, causal = False, pretrained = True )\n",
    "start_time = time.time()\n",
    "\n",
    "# freeze conv1, blocks layer\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.blocks.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 51, (1,1,1))\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_iter(model, optimz, train_loader, trloss_val)\n",
    "    evaluate(model, test_loader, tsloss_val)\n",
    " \n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "movi_hmdb_off.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10cf8cfbba5d408f905855995c502fba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15fb89fe0f454fd8a47316c5f4fe50a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10cf8cfbba5d408f905855995c502fba",
      "placeholder": "​",
      "style": "IPY_MODEL_fb81268f11db41f4a09cad4206a4e04a",
      "value": " 423/423 [03:30&lt;00:00,  2.01it/s]"
     }
    },
    "39ca1a3fed5c4067a020bd7027b9fbf1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b61dbd4f71341c494e63bcb49b88c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f092d9597ac040ea9fcb916366d9601d",
       "IPY_MODEL_7bce03ea6a5b43bb80ba628d56f9186e"
      ],
      "layout": "IPY_MODEL_6b2a611444834d86b77adbc33905df41"
     }
    },
    "3c70c93bde99420c84c0ad818b2dd7c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "44b5e75d46ce438ab9db0b47a0c71280": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4f419af9ec4e4605b7a5404dee09e33c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56c1bc4a801c41c29dbfb00237703ef4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6b2a611444834d86b77adbc33905df41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b644b36cff84c6aaa444a875be6555d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6db30d527fa94b16a6af19e80828d0e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7543a992a3274c5b944f31361d4ddc4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bce03ea6a5b43bb80ba628d56f9186e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b644b36cff84c6aaa444a875be6555d",
      "placeholder": "​",
      "style": "IPY_MODEL_efbd6c2745714793bef5f5dcdb8445f6",
      "value": " 14.5M/14.5M [00:00&lt;00:00, 68.8MB/s]"
     }
    },
    "7e42e2ea9cad463c8ebe2a54801218b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb87c19a53c40c5b74353d2ac6f0de6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd90692766a54f68bac4a1e19516349c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2724859dc7e48b29fcdb0ab75c75675": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e42e2ea9cad463c8ebe2a54801218b2",
      "placeholder": "​",
      "style": "IPY_MODEL_7543a992a3274c5b944f31361d4ddc4d",
      "value": " 423/423 [01:52&lt;00:00,  3.76it/s]"
     }
    },
    "d7162af7b4084a999cc709307e40616a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5cfea9b48b04fef9df36d118efd1722",
       "IPY_MODEL_15fb89fe0f454fd8a47316c5f4fe50a9"
      ],
      "layout": "IPY_MODEL_6db30d527fa94b16a6af19e80828d0e6"
     }
    },
    "df50195d063b402f93d8552336045c3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e74d503d808e4c5da75eff1d096590ad",
       "IPY_MODEL_d2724859dc7e48b29fcdb0ab75c75675"
      ],
      "layout": "IPY_MODEL_39ca1a3fed5c4067a020bd7027b9fbf1"
     }
    },
    "e74d503d808e4c5da75eff1d096590ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acb87c19a53c40c5b74353d2ac6f0de6",
      "max": 423,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56c1bc4a801c41c29dbfb00237703ef4",
      "value": 423
     }
    },
    "efbd6c2745714793bef5f5dcdb8445f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f092d9597ac040ea9fcb916366d9601d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd90692766a54f68bac4a1e19516349c",
      "max": 15224955,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44b5e75d46ce438ab9db0b47a0c71280",
      "value": 15224955
     }
    },
    "f5cfea9b48b04fef9df36d118efd1722": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f419af9ec4e4605b7a5404dee09e33c",
      "max": 423,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c70c93bde99420c84c0ad818b2dd7c6",
      "value": 423
     }
    },
    "fb81268f11db41f4a09cad4206a4e04a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
